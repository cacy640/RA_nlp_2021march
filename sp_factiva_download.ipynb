{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "\n",
    "Remember to download geckodriver to your local path and save it under the Firefox location!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import getpass\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to Factiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Factiva_nus_login():\n",
    "    ## Launch Firefox and Return Factiva Database from NUS Library\n",
    "    # NOTE: CHANGE your geckodriver path below\n",
    "    exepath = \"/Applications/Firefox.app\"\n",
    "    driver = webdriver.Firefox(executable_path=exepath)\n",
    "    driver.implicitly_wait(30)\n",
    "    driver.get(\"https://lib-nus-edu-sg.libproxy1.nus.edu.sg/eforms/factiva.html\")\n",
    "    print (\"Firefox Initialized\")\n",
    "    \n",
    "    ## Login to Factiva\n",
    "    #** staff portal **\n",
    "    # network_domain = driver.find_element_by_xpath(\"//select[@name='domain']/option[@value='NUSSTF']\").click()\n",
    "    # NOTE: REMEMBER TO CHANGE TO ** student portal **\n",
    "    network_domain = driver.find_element_by_xpath(\"//select[@name='domain']/option[@value='NUSSTU']\").click()\n",
    "    time.sleep(2)\n",
    "    # Userid and Password\n",
    "    userid = driver.find_element_by_xpath(\"//input[@name='user']\")\n",
    "    ID = input('Enter your userid without domain: ')\n",
    "    Password = driver.find_element_by_xpath(\"//input[@name='pass']\")\n",
    "    password = getpass.getpass('Enter your password_case-sensitive: ')\n",
    "    userid.send_keys(ID)\n",
    "    Password.send_keys(password)\n",
    "    log_in = driver.find_element_by_xpath(\"//input[@value='Login']\").click()\n",
    "    accept = driver.find_element_by_xpath(\"//input[@value='I Accept']\").click()\n",
    "    time.sleep(2)\n",
    "    forward = driver.find_element_by_xpath(\"//img[@src='continue.gif']\").click()\n",
    "    print('Login successfully')\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Newspaper Name and Get Search Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Factiva_keywords():\n",
    "    \n",
    "    # Input inequality and Similar Words\n",
    "    search_box = driver.find_element_by_xpath(\"//textarea[@class='ace_text-input']\")\n",
    "    key_words = 'social equity OR inequality OR fairness OR gini OR poverty OR unequal OR equal OR fair OR unfair OR fairly OR poor OR rich OR disadvantaged population OR inferior living environment OR backwardness OR desegregation OR unfairness OR jobless OR disempowerment OR inclusiveness OR joblessness OR apartheid OR inequality OR inclusivity OR democracy OR civilizational OR powerlessness OR insecurity OR neoliberalism OR illiteracy OR interdependence OR underrepresentation OR injustice OR repression OR disparity OR inequity OR underdevelopment OR inadequacy OR poverty OR dropout OR homelessness OR unfreedom OR enfranchisement OR disproportionality OR immiseration OR equality OR dispossession OR colonialism OR intergenerational OR discrimination OR unemployment OR subjugation OR oppression OR fatherlessness OR marginalization OR undervaluation OR impoverishment OR dehumanization'\n",
    "    search_box.send_keys(key_words)\n",
    "    time.sleep(2)\n",
    "    print ('keywords Done')\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newspapers in New York (TWSJ): \n",
    "\n",
    # "a) 'The Sun' \n",
    # "[01-01 to 06-30: 3049 unique articles; 07-01 to 12-31: 3130 unique articles] √\n",
    # "\n",
    # "b) 'The Daily Telegraph' ('The Sunday Telegraph') [01-01 to 06-30:3600 unique articles; 07-01 to 12-31: 3910 unique articles] √\n",
    # "\n",
    # "c) 'Daily Mail' ('The Sunday Mail') [01-01 to 06-30:1922 unique articles; 07-01 to 12-31: 2166 unique articles] √\n",
    # "\n",
    # "d) 'The Times' ('The Sunday Times') [01-01 to 06-30: unique articles; 07-01 to 12-31: 2166 unique articles]\n",
    # "\n",
    "a) 'The Wall Street Journal Online' [To do]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " def Factiva_search():\n",
    "        \n",
    "    # Set Language to English\n",
    "    language = driver.find_element_by_xpath(\"//*[@id='laTab']/div[1]\").click()\n",
    "    English = driver.find_element_by_xpath(\"//*[@id='laMnu']/ul/li[12]/a\").click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Set Date (Generally, serach result of half a year for a particular newspaper would not exceed 10000 articles.)\n",
    "    date = driver.find_element_by_xpath(\"//select[@id='dr']\").click()\n",
    "    date_range = driver.find_element_by_xpath(\"//select[@id='dr']/option[@value='Custom']\").click()\n",
    "    \n",
    "    # clear input if there are texts already\n",
    "    # NOTE: Remember to change start and end dates per half a year download\n",
    "    start_day = driver.find_element_by_xpath(\"//input[@id='frd']\").send_keys('01') \n",
    "    start_month = driver.find_element_by_xpath(\"//input[@id='frm']\").send_keys('01') # 01/07\n",
    "    start_year = driver.find_element_by_xpath(\"//input[@id='fry']\").send_keys('2020')\n",
    "    end_day = driver.find_element_by_xpath(\"//input[@id='tod']\").send_keys('01') # 30/31\n",
    "    end_month = driver.find_element_by_xpath(\"//input[@id='tom']\").send_keys('03') # 06/12\n",
    "    end_year = driver.find_element_by_xpath(\"//input[@id='toy']\").send_keys('2020')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Set Source Newspaper\n",
    "    source = driver.find_element_by_xpath(\"//*[@id='scTab']/a\").click()\n",
    "    newspaper = driver.find_element_by_xpath(\"//div[@class='lkpInput']/input[@id='scTxt']\")\n",
    "    newspaper_name = input ('newspaper_name: ')\n",
    "    newspaper.send_keys(newspaper_name)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Factiva_start():\n",
    "    driver.find_element_by_xpath(\"//input[@id='btnSearchBottom']\").click()\n",
    "    print ('loading result successfully')\n",
    "\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firefox Initialized\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your userid without domain:  e0140999\n",
      "Enter your password_case-sensitive:  Wjx980524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successfully\n"
     ]
    }
   ],
   "source": [
    "driver = Factiva_nus_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords Done\n"
     ]
    }
   ],
   "source": [
    "keywords = Factiva_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "newspaper_name: TWSJ\n"
     ]
    }
   ],
   "source": [
    "# NOTE: If error shows, rerun this line\n",
    "# NOTE: Remember to select the newspaper needed with the particular location in bracket after keying in the name to forward\n",
    "search = Factiva_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading result successfully\n"
     ]
    }
   ],
   "source": [
    "start = Factiva_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawling News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_judge1 = driver.find_element_by_xpath('//*[@id=\"headlines\"]/table/tbody/tr[1]/td[3]/a').text\n",
    "content_judge2 = driver.find_element_by_xpath('//*[@id=\"headlines\"]/table/tbody/tr[2]/td[3]/a').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_1 is loading\n",
      "page_1 is successfully loaded\n",
      "article_1 is crawling\n",
      "-----------------\n",
      "article_1 is done\n",
      "article_2 is crawling\n",
      "-----------------\n",
      "article_2 is done\n",
      "article_3 is crawling\n",
      "-----------------\n",
      "article_3 is done\n",
      "article_4 is crawling\n",
      "-----------------\n",
      "article_4 is done\n",
      "article_5 is crawling\n",
      "-----------------\n",
      "article_5 is done\n",
      "article_6 is crawling\n",
      "-----------------\n",
      "article_6 is done\n",
      "article_7 is crawling\n",
      "-----------------\n",
      "article_7 is done\n",
      "article_8 is crawling\n",
      "-----------------\n",
      "article_8 is done\n",
      "article_9 is crawling\n",
      "-----------------\n",
      "article_9 is done\n",
      "article_10 is crawling\n",
      "-----------------\n",
      "article_10 is done\n",
      "article_11 is crawling\n",
      "-----------------\n",
      "article_11 is done\n",
      "article_12 is crawling\n",
      "-----------------\n",
      "article_12 is done\n",
      "article_13 is crawling\n",
      "-----------------\n",
      "article_13 is done\n",
      "article_14 is crawling\n",
      "-----------------\n",
      "article_14 is done\n",
      "article_15 is crawling\n",
      "-----------------\n",
      "article_15 is done\n",
      "article_16 is crawling\n",
      "-----------------\n",
      "article_16 is done\n",
      "article_17 is crawling\n",
      "-----------------\n",
      "article_17 is done\n",
      "article_18 is crawling\n",
      "-----------------\n",
      "article_18 is done\n",
      "article_19 is crawling\n",
      "-----------------\n",
      "article_19 is done\n",
      "article_20 is crawling\n",
      "-----------------\n",
      "article_20 is done\n",
      "article_21 is crawling\n",
      "-----------------\n",
      "article_21 is done\n",
      "article_22 is crawling\n",
      "-----------------\n",
      "article_22 is done\n",
      "article_23 is crawling\n",
      "-----------------\n",
      "article_23 is done\n",
      "article_24 is crawling\n",
      "-----------------\n",
      "article_24 is done\n",
      "article_25 is crawling\n",
      "-----------------\n",
      "article_25 is done\n",
      "article_26 is crawling\n",
      "-----------------\n",
      "article_26 is done\n",
      "article_27 is crawling\n",
      "-----------------\n",
      "article_27 is done\n",
      "article_28 is crawling\n",
      "-----------------\n",
      "article_28 is done\n",
      "article_29 is crawling\n",
      "-----------------\n",
      "article_29 is done\n",
      "article_30 is crawling\n",
      "-----------------\n",
      "article_30 is done\n",
      "page_2 is loading\n",
      "page_2 is successfully loaded\n",
      "article_1 is crawling\n",
      "-----------------\n",
      "article_1 is done\n"
     ]
    }
   ],
   "source": [
    "# start page \n",
    "# NOTE: REMEMBER TO CHANGE PAGE INDEX IF YOU CHANGE TO DOWNLOAD TO THE SECOND HALF YEAR OF 2020\n",
    "# OR YOU CAN CHANGE LOCATIONS BELOW BY ADDING THE LAST FILE INDEX IN YOUR PREVIOUS FIRST HALD YEAR DOWNLOAD\n",
    "page_i = 0\n",
    "\n",
    "# start crawling articles\n",
    "while page_i <= 400:\n",
    "    page_i = page_i + 1 \n",
    "    time.sleep(2)\n",
    "    refresh_time = 0\n",
    "    while refresh_time <=5:     \n",
    "        content_judge1_1 = driver.find_element_by_xpath('//*[@id=\"headlines\"]/table/tbody/tr[1]/td[3]/a').text\n",
    "        content_judge2_2 = driver.find_element_by_xpath('//*[@id=\"headlines\"]/table/tbody/tr[2]/td[3]/a').text\n",
    "        refresh_time2 = 0\n",
    "        while (content_judge1 == content_judge1_1) and (content_judge2 == content_judge2_2) and (refresh_time <= 24):\n",
    "            print('page_' + str(page_i) + ' is loading')\n",
    "            time.sleep(5)\n",
    "            content_judge1_1 = driver.find_element_by_xpath('//*[@id=\"headlines\"]/table/tbody/tr[1]/td[3]/a').text\n",
    "            content_judge2_2 = driver.find_element_by_xpath('//*[@id=\"headlines\"]/table/tbody/tr[2]/td[3]/a').text\n",
    "            refresh_time = refresh_time + 1 \n",
    "            if page_i ==1:\n",
    "                break \n",
    "\n",
    "        if refresh_time <=24:\n",
    "            print('page_' + str(page_i) + ' is successfully loaded')\n",
    "            refresh_time = 10\n",
    "        else:\n",
    "            refresh_time = refresh_time + 1\n",
    "            driver.refresh()    \n",
    "            time.sleep(10)\n",
    "\n",
    "   \n",
    "    final = ''  \n",
    "    for i in range(1, 31):\n",
    "        # locate headlines\n",
    "        xpath = '//*[@id=\"headlines\"]/table/tbody/tr[' + str(i) + ']/td[3]/a'\n",
    "\n",
    "        load_time = 0 \n",
    "        while load_time <= 5:  \n",
    "            try:\n",
    "                # NOTE: IF THE LOOP STOPS HERE WITH 'NoSuchElementException' ERROR, RUN THE NEXT STEP AND SAVE CURRENT LOOP TO LOCAL PATH\n",
    "                driver.find_element_by_xpath(xpath).click() \n",
    "            except:\n",
    "                print ('download complete ^=^')\n",
    "                raise \n",
    "               \n",
    "                \n",
    "            time.sleep(3) \n",
    "\n",
    "            check = driver.find_elements_by_xpath(\n",
    "                '/html/body/form[2]/div[2]/div[2]/div[5]/div[2]/div[3]/div/div[2]/div/div[2]/div[2]')\n",
    "            wait_time = 0  \n",
    "            while len(check) == 0 and wait_time <= 10:\n",
    "                print('article_'+ str(i) + ' fails to load! Retrying!')\n",
    "                time.sleep(2)\n",
    "                check = driver.find_elements_by_xpath(\n",
    "                    '/html/body/form[2]/div[2]/div[2]/div[5]/div[2]/div[3]/div/div[2]/div/div[2]/div[2]')\n",
    "                wait_time = wait_time + 1  \n",
    "\n",
    "\n",
    "            if wait_time <= 10:\n",
    "                print('article_'+ str(i) + ' is crawling')\n",
    "                content = driver.find_elements_by_xpath(\n",
    "                    '/html/body/form[2]/div[2]/div[2]/div[5]/div[2]/div[3]/div/div[2]/div/div[2]/div[2]')[0].text\n",
    "                if content == '+ Related Dow Jones Intelligent Identifiers':\n",
    "                    content = driver.find_elements_by_xpath(\n",
    "                        '/html/body/form[2]/div[2]/div[2]/div[5]/div[2]/div[3]/div/div[2]/div/div[2]/div[3]')[0].text\n",
    "                else:\n",
    "                    pass\n",
    "                load_time = 6 \n",
    "            else:\n",
    "                driver.find_element_by_xpath('//*[@id=\"returnToHeadlines\"]/a').click() \n",
    "                time.sleep(1)\n",
    "                load_time = load_time + 1\n",
    "                print('article_'+ str(i) + 'is retrying')\n",
    "\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"returnToHeadlines\"]/a').click()  \n",
    "        except:\n",
    "            print('-----------------')  \n",
    "\n",
    "        content = content.replace('\\n\\n', '\\n')\n",
    "        content = content.replace(' \\n',' ')\n",
    "\n",
    "        final = final + '\\n\\n' + content\n",
    "        print('article_'+ str(i) + ' is done')\n",
    "\n",
    "    final = final.lstrip('\\n\\n')\n",
    "    # NOTE: Change to your path\n",
    "    location = 'C:/Users/BIZYUCG/Dropbox/Chang yuki/Natural Language Processing/data/London/The Guardian/' + 'The Guardian_' + str(page_i+358) + '.txt'\n",
    "    file = open(location, mode='w', encoding='utf-8')\n",
    "    file.write(final)\n",
    "\n",
    "    content_judge1 = driver.find_element_by_xpath('//*[@id=\"headlines\"]/table/tbody/tr[1]/td[3]/a').text\n",
    "    content_judge2 = driver.find_element_by_xpath('//*[@id=\"headlines\"]/table/tbody/tr[2]/td[3]/a').text\n",
    "    if page_i <=1:\n",
    "        driver.find_element_by_xpath('//*[@id=\"headlineHeader33\"]/table/tbody/tr/td/a').click() \n",
    "    else:\n",
    "        driver.find_element_by_xpath('//*[@id=\"headlineHeader33\"]/table/tbody/tr/td/a[2]').click()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305045"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: SAVE THE LAST BATCH WITH LESS THAN 30 ARTICLES \n",
    "final = final.lstrip('\\n\\n')\n",
    "location = '/Users/jiaxuan/Desktop/RA project/NLP/NYC_paper/200101_200301' + 'TWSJ_' + str(page_i+358) + '.txt'\n",
    "file = open(location, mode='w', encoding='utf-8')\n",
    "file.write(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
